---
title: 自旋锁(spinlock)
layout: post
tags: spinlock linux lock
category: coding
---

wikipedia上对[spinlock](http://en.wikipedia.org/wiki/Spinlock)做了不错的解说. 此处做一些摘引.
> * 在线程编程中，spinlock是这样的一种lock，线程循环地等待(spins)加锁，直到lock available。  
> * 可知，spinlock属于[busy waiting](http://en.wikipedia.org/wiki/Busy_waiting)。  
> * spinlock更适合执行时间短的任务，因此能够避免操作系统进程调度和context切换的时间。对于执行时间较长的任务，spinlock的效率可能很低，因为在线程被调度出CPU的时候，spinlock并不能被其他要求进入同一critical section的线程获得。  
> * 正确实现spinlock机制不是一件容易的事情，一般来说，spinlock只能方便地由特殊的汇编指令(如原子性的test-and-set指令)实现。

[冠诚](http://guancheng.42qu.com/)在他的博文["pthreads 并行编程之 spin lock 与 mutex 性能对比分析"](http://www.parallellabs.com/2010/01/31/pthreads-programming-spin-lock-vs-mutex-performance-analysis/)中详细比较了**mutex(sleep-waiting)**和 **spinlock(busy-waiting)**的性能，他的总结是：  
> 1.Mutex适合对锁操作非常频繁的场景，并且具有更好的适应性。尽管相比spin lock它会花费更多的开销（主要是上下切换），但是它能适合实际开发中复杂的应用场景，在保证一定性能的前提下提供更大的灵活度.  
> 2.spin lock的lock/unlock性能更好(花费更少的cpu指令)，但是它只适应用于临界区运行时间很短的场景。而在实际软件开发中，除非程序员对自己的程序的锁操作行为非常的了解，否则使用spin lock不是一个好主意(通常一个多线程程序中对锁的操作有数以万次，如果失败的锁操作(contended lock requests)过多的话就会浪费很多的时间进行空等待).  
> 3.更保险的方法或许是先（保守的）使用 Mutex，然后如果对性能还有进一步的需求，可以尝试使用spin lock进行调优。毕竟我们的程序不像Linux kernel那样对性能需求那么高(Linux Kernel最常用的锁操作是spin lock和rw lock)。

linux 中的 [spinlock](http://www.mjmwired.net/kernel/Documentation/spinlocks.txt).

---

*[2012-11-02 updated]: ldd3 5.5 "spinlocks"*

spinlocks不同于信号量，它可以使用在不能睡眠的代码中，比如interrupt handlers。用的好时，spinlocks可以带来比信号量更好的性能；但spinlocks也要遵循一些约束。

spinlocks的原理是简单的，一般被实现为int值的一位。只提供两种逻辑：加锁和解锁。可以想见加锁是类似于“test-and-set”实现的。  
spinlocks是忙等的。  

spinlocks的使用大致如下：  
静态初始化：spinlock_t my_lock = SPIN_LOCK_UNLOCKED;  
动态初始化：void spin_lock_init(spinlock_t \*lock);  
加锁(进入critical section之前):void spin_lock(spinlock_t \*lock);  
解锁：void spin_lock(spinlock_t \*lock);  

**spinlocks需要遵循的3条约束**  

【场景一】线程持有spinlock时，处理器被其他进程“抢”去：  
1、假设某个驱动程序获得一个spinlock，开始执行critical section里面的代码。  
2、还没有执行完的时候，驱动程序丢失了对处理器的使用权。可能的原因有很多：比如驱动调用了可能睡眠的函数(copy_from_user)；比如内核抢占发生，一个更高优先级的进程抢占了处理器。  
3、驱动仍然持有这个spinlock，此时如果又其他线程尝试获取同一个spinlock时，这个“其它线程”可能会等一段很长的时间，甚至会引起死锁。  

要避免这样的场景。因此一般原则是持有spinlock的代码要是原子的，即不能睡眠。  
不过场景中描述的内核抢占问题，是spinlock自己解决的。任何时候当内核代码持有spinlock时，内核抢占在相关的处理器上是取消(disabled)的，即不会睡眠。  
> The kernel preemption case is handled by the spinlock code itself. Any time kernel code holds a spinlock, preemption is disabled on the relevant processor. Even uniprocessor systems must disable preemption in this way to avoid race conditions. That is why proper locking is required even if you never expect your code to run on a multiprocessor machine.

持有锁时防止睡眠，要解决这个问题麻烦得多。很多内核函数可以睡眠，并且这些行为都没有很好地记录下来，所以使用spinlock时，要特别关注critical section中调用的每个函数。

【场景二】线程持有spinlock时，处理器被interrupt handler抢去：  
1、假设一个驱动程序正持有spinlock，此时设备发生中断，中断处理程序被激发。  
2、interrupt handler恰好也要获得同一spinlock（interrupt handler获取spinlock是一件合情合理的事情，这也就是为什么持有spinlock时不睡眠的原因，持有spinlock时，就你这个进程能跑，其他进程免谈，当然中断另算）。  
3、如果interrupt handler也在同一处理器上执行，这就造成死锁了，这个处理器将一直spin。  

防止这种情况需要在持有spinlock的处理器上禁止中断，有多个函数可以达到这个目的。  
spin\_lock\_irqsave()，加锁前，在本地处理器(local processor，应该指spinlock所在的哪个处理器)上禁止中断。旧的interrupt state保存在flags里面。  
spin\_lock\_irq()：类似于spin_lock_irqsave，区别是，如果你确定只有你一个人会在本地处理器上禁止中断，即你确定在你释放spinlock时，中断肯定会被重新开启，你可以使用spin_lock_irq，从而不必记录flags。  
spin\_lock\_bh()：加锁前，禁止软件中断，硬件中断仍然是开启的。  

如果你有一个spinlock会被中断上下文加锁，你就必须使用上面的某个函数禁止中断，否则可能带来死锁。

【约束之三】持有spinlock的时间要短，长时间持有spinlock，使得当前处理器长时间不能够schedule，使得更高优先级的进程必须等待，引起系统整体性能下降。