---
title:   [Tair源代码分析<3>]
layout: post
category: tair
---
<script src="https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js?lang=cc&skin=sunburst"></script>
###写在最前面
在<a href="http://fengmao.github.io/tair/2013/04/20/TAIR源码分析_2.html" target="_blank">TAIR源代码分析&lt;2&gt;</a>中，描述了configserver创建对照表的过程。本文将阐述tair是如何完成数据迁移的。
</p>
##2.6  Tair数据迁移的机制
关于Tair的数据迁移机制， 本文所描述的是Tair集群内部的数据迁移，不包括主备集群间的数据迁移。有以下几点需要注意：
<ul>
<li>作为缓存使用，数据通常只保留一份。在这种情况下，系统无需数据迁移机制，因为宕机后，其存储的数据必定丢失;</li>
<li>Tair的数据进行多备份存储时，可配置允许数据丢失。在这种情况下，也无需数据迁移机制；</li>
<li>Tair的数据进行多备份存储，配置不允许数据丢失。在这种情况下，需要通过数据迁移机制恢复。</li>
</ul>

在分布式系统里，如何保证数据安全? 通常的办法是对数据进行多备份存储。Tair也不例外，以bucket为单位进行多备份存储，保证数据安全。Tair的数据备份数是可配置的，当配置项copyCount为1的时候，表示系统中只保存一份数据，不存在备份，这种情况下，是不需要数据迁移功能的。当copyCount大于1的时候，并且配置了允许数据迁移，那么数据迁移的功能才会在必要的时候发挥作用。
</p>
<p>
本文为了描述Tair数据迁移机制，假定配置项中copyCount&gt;1,且允许数据迁移。章节安排如下：2.6.1节描述Tair系统为什么需要数据迁移；2.6.2节描述 （这里先空下，现在也不确定。写出来，简明易懂，还是比较有挑战的，特别是对我这样不善于玩文字的人来说~~）。
</p>
###2.6.1 为什么需要数据迁移

在创建对照表的章节中，我们知道master bucket和slave bucket是不会全部存储在同一个物理节点上的。当某一个物理节点不可用后，那么存储在这个节点上的所有bucket都会丢失。在这些丢失的bucket中，有master bucket和slave bucket。若master bucket丢失后，该bucket的某个slave bucket会变成master bucket；那么，系统为了保证每个bucket存储copyCount份，会在其他可用节点上创建一个bucket, 进行数据迁移（复制）。

###2.6.2 数据迁移触发条件
在Tair集群中配置服务器(CS)负责创建对照表，也是CS通过心跳来管理集群所有的数据服务器（DS）。当有数据服务器宕机后，最先获取该信息的应该是CS 。还是通过代码入手吧，代码不会欺骗我们。
为了减少篇幅与排版，我只保留重要的代码片。
<pre class="prettyprint lang-cc">
void server_conf_thread::run(tbsys::CThread * thread, void *arg)
{
  //这里略去判断主备CS的代码，以及读取配置文件
  // will start loop
  uint32_t loop_count = 0;
  tzset();
  int log_rotate_time = (time(NULL) - timezone) % 86400;
  struct timespec tm;
  clock_gettime(CLOCK_MONOTONIC, &tm);
  heartbeat_curr_time = tm.tv_sec;
  is_ready = true;

  //线程主循环
  while(!_stop) {
    struct timespec tm;
    clock_gettime(CLOCK_MONOTONIC, &tm);
    heartbeat_curr_time = tm.tv_sec;
    for(size_t i = 0; i < config_server_info_list.size(); i++) {
      server_info *server_info_it = config_server_info_list[i];
      if(server_info_it->server_id == util::local_server_ip::ip)
        continue;
      if(server_info_it->status != server_info::ALIVE
          && (loop_count % 30) != 0) {
        down_slave_config_server = server_info_it->server_id;
        continue;
      }
      //向对端CS发心跳包,可以看出这个心跳包比较简单
      down_slave_config_server = 0;
      request_conf_heartbeart *new_packet = new request_conf_heartbeart();
      new_packet->server_id = util::local_server_ip::ip;
      new_packet->loop_count = loop_count;
      if(connmgr_heartbeat->
          sendPacket(server_info_it->server_id, new_packet) == false) {
        delete new_packet;
      }
    }

    loop_count++;
    if(loop_count <= 0)
      loop_count = TAIR_SERVER_DOWNTIME + 1;
    uint32_t curver = get_file_time(group_file_name);
    if(curver > config_version_from_file) {
      //如果发现配置文件版本发生来变化，需要重新读取配置文件内容，后续在分析这个函数
      load_group_file(group_file_name, curver, 0);
      config_version_from_file = curver;
      //将配置信息发送到另外一个CS，如果存在的话
      send_group_file_packet();
    }

    //这个函数检查对端CS当前的状态, 例如主CS宕机，这个函数是能够检查到的
    check_config_server_status(loop_count);

    //检查数据服务器的状态,这里是以group为单位，检查group内的数据服务器状态，如果由变化，则创建该group的对照表
    if(loop_count > TAIR_SERVER_DOWNTIME) {
      check_server_status(loop_count);
    }

    //睡眠1s
    TAIR_SLEEP(_stop, 1);
  }
  is_ready = false;
}
</pre>
总结下，这个段代码是CS中的一个线程的RUN函数，该线程循环主要作了3件事情：
<ul>
<li>给另外一个CS发送心跳包，如果对方存在的话；</li>
<li>检查另外一个CS的状态, 判断是否要发生主配置服务器发生改变;</li>
<li>检查数据服务器的状态，判断是否需要重建对照被；</li>

与数据迁移机制相关的是check_server_status函数，该函数的主要功能是通过心跳来判断DS当前是否宕机，或者由DS恢复过来。简单的说，就是通过心跳机制
来判断活着的DS是不是死了。接下来还是看看这个函数吧：
<pre class="prettyprint lang-cc">
 void server_conf_thread::check_server_status(uint32_t loop_count)
{
  set<group_info *>change_group_info_list;

  //检查group是否需要重建对照表
  group_info_map::iterator it;
  for(it = group_info_map_data.begin(); it != group_info_map_data.end();
      ++it) {
    if(it->second->is_need_rebuild()) {
      change_group_info_list.insert(it->second);
    }
  }

  server_info_map::iterator sit;
  for(sit = data_server_info_map.begin();
      sit != data_server_info_map.end(); ++sit) {
    //a bad one is alive again, we do not mark it ok unless some one tould us to.
    //administrator can touch group.conf to let these data serve alive again.
    uint32_t now;                // this decide how many seconds since last heart beat, we will mark this data server as a bad one.
    if(sit->second->group_info_data) {
      now =
        heartbeat_curr_time -
        sit->second->group_info_data->get_server_down_time();
    }
    else {
      now = heartbeat_curr_time - TAIR_SERVER_DOWNTIME;
    }
    //CS记录最近一次接收到DS心跳包的时间戳，若从这个时间点超过TAIR_SERVER_DOWNTIME(4s)时间, 并且也无法ping通，仍没有收到其心跳包
    //就认为失去来联系了，CS需要做点什么的时候了
    //判断或者的DS是不是挂掉了
    if(sit->second->status != server_info::DOWN) {
      if((sit->second->last_time < now && (sit->second->status == server_info::ALIVE && !tbnet::ConnectionManager::isAlive(sit->second->server_id))) || sit->second->status == server_info::FORCE_DOWN) {        // downhost
        change_group_info_list.insert(sit->second->group_info_data);
        sit->second->status = server_info::DOWN;
        if(master_config_server_id == util::local_server_ip::ip) {
          sit->second->group_info_data->pending_failover_server(sit->first);
        }

        // if (need add down server config) then set downserver in group.conf
        if (sit->second->group_info_data->get_pre_load_flag() == 1)
        {
          sit->second->group_info_data->add_down_server(sit->second->server_id);
          sit->second->group_info_data->set_force_send_table();
        }
      }
    }
  }
  // 只有主CS才去重建对照表，并将对照被同步给备CS，保持对照被的一致性
  // 若是备份CS运行的话，到这里该结束来
  if(master_config_server_id != util::local_server_ip::ip) {
    return;
  }

  uint64_t slave_server_id = get_slave_server_id();

  //简单检查下迁移任务是否完成了, 之所以说是简单，因为就是对比一下2分对照表，接下来还有更相信的检查
  group_info_rw_locker.rdlock();
  if(loop_count % HARD_CHECK_MIG_COMPLETE == 0) {
    for(group_info_map::const_iterator it = group_info_map_data.begin();
        it != group_info_map_data.end(); it++) {
      it->second->hard_check_migrate_complete(slave_server_id);
    }
  }
  group_info_rw_locker.unlock();

  //检查数据迁移与数据恢复
  for(it = group_info_map_data.begin(); it != group_info_map_data.end();
      ++it) {
    it->second->check_migrate_complete(slave_server_id, &group_info_rw_locker);
    it->second->check_recovery_complete(slave_server_id, &group_info_rw_locker);
  }

  //同步对照表到备CS
  group_info_rw_locker.rdlock();
  for(it = group_info_map_data.begin(); it != group_info_map_data.end();
      ++it) {
    // check if send server_table
    if (1 == it->second->get_send_server_table())
    {
      it->second->send_server_table_packet(slave_server_id);
      it->second->reset_force_send_table();
    }
  }

  //若没有Group发生变化，就返回吧
  if(change_group_info_list.size() == 0U) {
    group_info_rw_locker.unlock();
    return;
  }

  //若有Group发生变化，将该group交给builder_thread线程
  //这里将实质性地触发对照被重建;
  //server_conf_thread 检查变化来的Group, 将Group提交给builder_thread线程，前者是生产者，后者是消费者
  set<group_info *>::iterator cit;
  tbsys::CThreadGuard guard(&mutex_grp_need_build);
  for(cit = change_group_info_list.begin();
      cit != change_group_info_list.end(); ++cit) {
    builder_thread.group_need_build.push_back(*cit);
    (*cit)->set_table_builded();
  }
  group_info_rw_locker.unlock();
}
</pre>

上述函数将触发建对照表线程，创建对照表。至此，我们再来回顾下：
首先，可通过配置文件来决定是否允许系统发生数据迁移。下文讨论中，均假设允许数据迁移。<span style="line-height:1.5;font-size:10pt;">我们知道，当可用节点发生变化后（有意或意外添加/减少可用节点会导致可用节点发生变化），configserver会重建对照表。回忆下创建对照表那节，每次创建对照表会输出3张表，其中将一张描述当前bucket分布的对照表，和一张描述迁移完成后的bucket分布的对照表发给每一个物理节点。

新创建的对照表后，configserver与节点之间通过心跳包将新的对照表，对照表版本号以及其他信息发送给存储节点。在2.5.*节中，阐述了对照表如何创建的，这里，强调了对照表何时发送给存储节点的。另外一方面，configserver需要记录哪些节点要完成数据迁移工作。相当于，作为管理者，它要作一个记录，否则，它无法知道系统是否干完了数据迁移的活。


按照2.5节的假设，现在又对照表如表2所示，从左到右，依次为hash_table, m_hash_table和d_hash_table。假设节点D意外不可用，那么configserver检测到节点D不可用后，触发重建对照表过程。假设我们配置的是负载均衡优先的建表策略，新建对照表如表3所示。可以看出，在新建对照表的第1份和第2份中存储“空”表项，在程序中这里存储的是0。新建对照表后，已经彻底没有了节点D的踪影了。

3份对照表
<p align=center><img src=/images/tair-3/t1.png width=401></p>
表2 对照表
重建后的3份对照表
<p align=center><img src=/images/tair-3/t2.png width=400></p>

根据对照表3，configserver如何发现那些节点需要迁移呢? 这个工作由groupinfo::fillmigratemachine函数来完成的。具体地，该函数通过对比对照表的mhashtable和dhashtable来判断那些节点有数据迁移任务。判断方法很直观，对比 mhashtable和dhashtable的存储slave bucket的表项。对于某一个bucket, 对比其slave bucket表项，在 mhashtable和dhashtable内容是否相同（顺序可不同），若存在差异，在该bucket需要迁移，并且master bucket所在机器负载迁移任务。configserver将这一信息记录起来。举例说明，第0个bucket(表3中加粗）, 在mhashtable中slave bucket项为{“空”，B}，而在dhashtable中的表项为{A,B}。显然{"空“,B}和{A,B}是不同的。因此，第0个bucket需要迁移，由节点C完成迁移工作。这里再多说点，若在mhash_table中的表项为{B,A}，那么，这个节点就不需要迁移了。为什么？想一想吧，很简单哦。fillmigratemachine主要是configserver从全局层面，统计需要迁移的bucket信息。
上述功能由group_info::fill_migrate_machine函数实现，代码很简洁，这里就没有上代码的必要来。

至此，configserver创建了对照表，并且记录了哪些存储节点有迁移任务。当某个节点完成迁移后，它就主动向configserver报告。这里没有采用configserver去轮训存储节点，应该是处于效率考虑的。
v次注意e2和表3，从全局上来看，节点D不可用后，需要迁移的Bucket编号为{0,1,2,3,4}。由于这个例子比较特殊，1个节点不可用后，会导致所有bucket均发生数据迁移。在线上环境中，通常bucket的数量要远远大于节点的数量。当一个存储节点不可用后，只会导致部分节点发生迁移，而不是所有节点发生迁移。


###2.6.3 存储节点完成迁移任务
从上一节中，我们知道configserver记录了哪些节点需完成bucket的迁移工作。那么，存储节点如何感知自己迁移哪些bucket，并将bucket迁移至何方呢？configserver没有直接告诉存储节点，而是告诉了存储节点当前bucket分布表，和迁移完成后的bucket分布表。那么，根据这2个分布表，存储节点完全知道自己需要迁移那个bucket,并且将bucket迁移至何处。新启动的线程，通过调用pthread_detach(pthread_self())来确保其父线程不会阻塞在更新对照表这个过程中。也就是说，在更新对照表的过程中，tair还是可以对我提供服务的。

Tair数据迁移是按bucket为单位来迁移的。一个存储节点可能存储一个或者多个 master bucket 和 slave bucket。通过上面分析，我们知道了存储节点如何知道哪些bucket需要迁移，并且具体bucket有哪些存储节点发起迁移。 我们假设节点N， 需要迁移bucket B到另外一个节点X。接下来，我们分析这个迁移过程是如何完成的。

Tair的存储节点通过一个后台线程，来完成bucket的迁移任务。迁移数据的过程中，存储节点需要继续对外提供读写服务。对于读操作而言，节点根据请求的key, 到存储节点中读取数据并返回给应用。对写操作（ 包括write, delete等），存储节点会检查key对应的bucket是否已经迁移完毕（即该bucket迁移到了其他节点上了），若已迁移，则直接返回用户一个返回码，表示当前写操作没有成功。
>这里小问题，客户端根据key的hashcode来确定所在bucket, 再通过对照表来确定bucket所在存储节点。那么，怎么会出现bucket已经迁移完成，而请求还发送至其以前所在的节点上呢？ 这是因为客户端并没有拿到最新的对照表。

当bucket正在迁移，并且没有结束的时候，写操作将数据写入存储引擎，并且将将日志写入磁盘。写操作日志格式为<{PUT, DELETE}, KEY, [VALUE]>。

后台线程，首先迁移bucket中的数据。在整个bucket迁移的过程中，属于该bucket的数据可以分为2类：1）迁移启动前bucket中已有的数据；2）在迁移过程中，新写入的数据（新写入的数据记录日志记录）。对于第1）类数据，直接从存储引擎中读出，并通过TCP连接发送到目的节点。对于第2）类数据，需要通过迁移日志，目的节点收到日志后，回放日志，从而达到数据迁移的目的。

这里有个问题，由于迁移过程中对外提供写服务，有什么机制保证迁移过程能够结束？在迁移过程中，写日志，存储节点的性能受到影响？ 有什么办法可以减轻这种影响？



####2.6.3.1 更新对照表
configserver创建好对照表后，通过心跳机制，将对照表分发给每一个存储节点。存储节点在收到对照表后，会对对照表的版本作检查。若检测到心跳信息中的对照表版本大于本地保存的对照表版本数（对照表版本数是依次递增的）， 会启动一个线程，更新对照表，并完成数据迁移工作。具体分析下存储节点更新对照表的代码，见代码注释。为了减少篇幅，我将略去部分不影响理解整体逻辑的部分代码。

<p align=center><img src=/images/tair-3/do_update_table.png width=397></p>

上述代码中，主要完成了对照表的新旧替换，完成了一些数据的统计，这些数据包括，本存储节点新增的bucket情况，不再存储的bucket情况，以及需要迁移的bucket情况。

####2.6.3.2 收集需要迁移的bucket的信息

对照表更新后，很容易判断出那些bucket需要迁移, configserver记录了所有需要迁移的bucket信息。存储节点拿到对照表后，会分析出自己需要迁移的bucket编号，以及bucket迁移的目标节点。实际上，对于每一个bucket而言，都存在对应的节点存储其master bucket。只有master bucket所在的节点才会负责该bucket的是否进行迁移。 这个是合理的，因为读更新（写，删除）操作也是首先作用在master bucket所在节点上，然后在同步到slave bucket所在的节点。这个逻辑体现在do_update_tableh函数的第行处。

假设一个节点负责一_master bucket, 那么该节点如何确定该节点是否需要迁移，若迁移，迁移的目标节点时那里？ 原理比较直观。在mehash_table中，有该bucket的master bucket和slave bucket所在的节点信息，以及该bucket在d_hash_table中所在的节点信息。结合表3， 例如第0号bucket在m_hash_table中的位置信息为T1={C, "空", B}, 在d_hash_table中的位置信息为：T2={C, A, B}。对于该bucket而言，对照表发生变化后，导致其master/slave bucket的存储节点位置发生了变化，需要迁移，并且迁移的地址目标节点为A。这里需要注意的是，程序检查bucket的对照表更新前后位置信息的时候，忽略其slave bucket存储位置在对照表中的次序关系。怎么理解? 例如，某bucket的2次位置信息T1={C,D,A}， T2={C, A, D}，这种情况下，是不会有数据迁移的。存储master bucket的节点会记录迁移信息<bucket_id, target_node>信息， 本来而言，节点C会记录这样信息：<0, A>。实现该逻辑的代码很简洁，请看代码：
<pre class="prettyprint lang-cc">
void table_manager::calculate_migrates(uint64_t *table, int index)
{  
  uint64_t* psource_table = table;
  uint64_t* pdest_table = table + get_hash_table_size();
  for (size_t i = 0; i &lt; this-&gt;copy_count; ++i) {

    bool need_migrate = true;
    uint64_t dest_dataserver = pdest_table[index + this-&gt;bucket_count * i];

    for (size_t j =0; j &lt; this-&gt;copy_count; ++j)     {    
      if (dest_dataserver == psource_table[index + this-&gt;bucket_count * j]) { 
        need_migrate = false; 
        break; 
      }     
    }    
    //记录迁移信息。
    if (need_migrate) {
      log_debug("add migrate item: bucket[%d] =&gt; %s", index, tbsys::CNetUtil::addrToString(dest_dataserver).c_str());
      migrates[index].push_back(dest_dataserver);
    }    
  }
  bucket_server_map_it it = migrates.find(index);
  if (it == migrates.end())
  {
    if (psource_table[index] != pdest_table[index])
    {    
      //this will add a empty vector to migrates,
      //some times only need to change master for a bucket
      migrates[index];
    }    
  }
}
</pre>

####2.6.3.3 数据迁移

在上一节中，对照表重建后，若发送数据迁移，负责master bucket的节点会知道将该bucket迁移至哪一个目标节点。有了这些信息后，该节点就会迁移数据。由于迁移数据的过程中，是不能停止对我服务的。这里就有个问题，某个bucket的数据正在迁移，若有读写请求怎么处理？ 对于，写，删除请求， 除外完成据请求外，还将日志记录在本地磁盘中。这些操作日志中记录了&lt;操作类型{PUT,REMOVE}, KEY, VALUE&gt;数据。在作为&lt;key,value&gt;的迁移后，还需要作为操作日志的迁移。目标节点收到迁移数据后，写入本地，收到操作日志后，回访日志，以保证数据一致性。

====================================

上午开发机挂了，无法干活儿，就继续我的代码分析工作。将之前写的内容重新整理，添加了部分新的内容。关于数据迁移部分，还有很多细节需要去理清。等理清后，补充完整。
