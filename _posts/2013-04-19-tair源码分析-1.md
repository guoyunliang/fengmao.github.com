---
title:  [Tair源代码分析<1>]
layout: post
category: tair
tags: tair
---
<script src="https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js?lang=cc&skin=sunburst"></script>
##写在最前面
我加入TAIR组后，曾试图写TAIR源码分析。后来，有新任务了，就把这个事情放下了。现在，随着工作的进展，我觉得非常有必要继续这个任务。于是，有了以下博文。这些博文，或许写的不准确，但是，我会一致维护下去，完善之。 欢迎大家拍砖，有砖尽管扔。本文，最初写在CSDN，后又移到OSCHINA。[link](http://my.oschina.net/tfengmao/blog/111399)

##概述 
Tair是分布式、高性能、可扩展、搞可靠性的存储系统。目前，Tair已成为开源项目，代码请移步到淘宝开源[click here](http://code.taobao.org/p/tair/src/)。关于Tair的更多介绍，见[TAIR wiki](http://code.taobao.org/p/tair/wiki/index/)。

##1. 代码结构
简要介绍Tair的代码结构，如下所示：
<pre class="prettyprint">.
   |-- AUTHORS
   |-- COPYING
   |-- ChangeLog
   |-- Makefile.am
   |-- NEWS
   |-- README
   |-- bootstrap.sh
   |-- configure.ac
   |-- contrib
   |-- doc
   |-- packages
   |-- rpm 
   |-- scripts
   |-- share
   |-- src 
   |   |-- Makefile.am
   |   |-- client
   |   |-- common
   |   |-- configserver
   |   |-- dataserver
   |   |-- invalserver
   |   |-- packets
   |   |-- plugin
   |   |-- statserver
   |   |   |-- Makefile.am
   |   |   |-- include
   |   |   `-- storage
   |   |-- storage
   |   |   |-- fdb
   |   |   |-- kdb
   |   |   |-- ldb
   |   |   |-- mdb
   |   |   `-- storage_manager.hpp
   |   `-- tools
   |-- tcmalloc.m4
    `-- test
   </pre>
整个系统的主要代码集中在src目录下。在该目录下, 每个目录简要介绍：
<ul>
<li> client目录中包含了c++客户端的所有代码，应用通过该客户端访问Tair系统;</li>
<li> commmon目录中包含了一些工具函数或者共用的C++类的实现;</li>
<li> configserver中包含了配置服务实现的代码;</li>
<li> dataserver中包含了数据服务器的代码实现;</li>
<li> invalserver目录中包含了失效服务器的实现代码;</li>
<li> storage目录中包含了Tair底层所使用的存储引擎,目前Tair主要使用2中存储引擎——mdb，leveldb;</li>
<li> tools目录中包含了部分系统运维工具;</li>
<li> test目录中包含了测试文件。</li>
</ul>

Tair系统还依赖底层网络编程库——tbnet,tbsys.这两个底层库提供了网络通信，配置文件管理，等基础功能；这里就不一一介绍了, 更多信息请进[tb-common-utils open source](http://code.taobao.org/p/tb-common-utils/src/)。
##2.配置服务器
###2.1 main
配置服务器（下文称为configserver)是tair系统的中心节点。该节点提供全局信息管理功能，通过主备机制实现中心节点的高可用性。在Tair系统中，configserver提供了哪些功能呢？configserver具有对对照表（server table)的管理，维护主备配置服务器之间的心跳，维护配置服务器与数据服务器之间的心跳，对数据迁移的管理，以及其他的全局信息管理。下文以这些功能为线索，进行代码分析。
接下来就先分析该服务器的main函数吧，代码如下：
<pre class="prettyprint lang-cc">
int main(int argc, char *argv[])
  {
    char *config_file = parse_cmd_line(argc, argv);
    if(TBSYS_CONFIG.load(config_file)) {
      return EXIT_FAILURE;
    }
    if(!tbsys::CFileUtil::mkdirs(dir_path)) {
     return EXIT_FAILURE;
   }   
   if(tbsys::CProcess::startDaemon(sz_pid_file, sz_log_file) == 0) {
     tair_cfg_svr = new tair::config_server::tair_config_server();
     tair_cfg_svr->start();     
     delete tair_cfg_svr;
   } 
  return EXIT_SUCCESS;
  }
</pre>
为了方便分析，上述代码经过精简的。可以看出，main函数在加载配置文件内容到内存，创建工作目录，将本线程设置为后台线程。接着，创建tair::config_server对象，调用start函数，configserver就在完成初始化后，就开始对外提供服务了。

> configserver是Tair系统的管理节点，为了避免单点失败，采用主备结构来保证高可用性。这里需要注意的是，configserver不会成为整个系统的性能瓶颈。客户端通过configserver来获取对照表数据，但是，客户端不会主动询问configserver，对照表版本是否变化了，是否需要读取新的对照表，而是通过读写操作的过程中，从存储节点处拿到对照表的版本，若发现对照表版本发生了变化，才去主动从CS拉取最新对照表数据。这样能够显著减少configserver的压力。

###2.2 configserver初始化
<p>
configserver的初始化工作在config_server::start函数中完成。如图所示，初始化完成如下工作：
<ul>
<li>读取配置文件内容，该函数由initialize()完成；</li>
<li>开一个线程池，该线程池处理应用发过来的请求，线程数可在配置文件中设定，由task_queue_thread.start()完成;</li>
<li>监听心跳端口;</li>
<li>监听服务端口;</li>
<li>启动my_server_config_thread线程，该线程完成CS大多数功能, 如对照表管理，检测存储节点状态等;</li>
<li>等待所有线程结束;</li>
<li>所有线程结束后，作最后清理工作;</li>
</ul>
初始化工作主要有start中完成的。该函数首先启动线程池，该线程池用于处理各种请求；打开2个TCP端口，一个用于处理对外提供服务，另外一个用于主备configserver之间的心跳；再开一个称为my_server_conf_thread的线程。接下来，看看该线程的初始化所在的事情：
</p>

<p align=center><img src=/images/tair-1/tair_config_server_start.png width=600 height=350></p>

后端server通常通过启动若干线程，各线程各司其职，对外提供服务。configserver也不例外，启动后，建立了若干线程，这些线程相互合作，又分工明确，共同对外提供服务。简单的来看，configserver创建的线程大概可以分为2类，“常驻线程”和 “临时线程”，前者的生存周期和server的生命周期相同，后者只是为了完成特定功能而建立的线程，工作完成后，线程就销毁了。这里就主要总结下configserver的“常驻线程”吧。
在初始化的过程中我们以下几种常驻线程：
<ul>
<li>1) 有2个tranport对象，该对象监听特定端口，管理TCP链接。每个transport有2个线程，一个负责接受新链接，并接受请求包，一个负责超时检查。</li>
<li>2) task_queue_thread对象，这是一个线程池，维护一个并发队列，transport对象将接收到的请求包放入该线程池的并发队列中，线程池中的线程取出请求包，并处理掉。</li>
<li>3) config_server_thread线程，该线程建立了一个循环，周期性检查各个group的状态，与另外一个configserver通过心跳包通讯；</li>
</ul>
task_queue_thread.start,在没有请求请求来的情况下，就会等待；packet_transport, heartbeat_transport.start后，将接受到的请求，放入到线程池队列中，工作线程处理请求。因此这两类线程的线程循环比较简单，并且不在本文分析范围内。本文分析my_server_conf_thread线程的线程循环，以窥探其功能。该线程的run函数做如下工作：
<ul>
<li>1)读取配置文件，建立保存group信息的数据结构，这些信息包括该group的数据服务器列表等；</li>
<li>2)如果主配置服务器存在并且alive,备配置服务器从主配置服务器上读取group的配置信息，而不是从配置文件中读取; </li>
<li> 3)建立循环，循环做如下事情：
<ul>
<li>a)检查group的配置文件版本信息，确定是否要重新读取配置文件；</li>
<li>b)检查group的对照表，确定是否要重新建立对照表，若需重建，设置重建标志；</li>
<li>c)检查配置服务器的状态；</li>
<li>d)检查数group的数据服务器的状态；</li>
</ul>
</li>
</ul>
贴上该线程的run函数的主要代码，代码中添加了注释，以便理解：

![alt tair_conf_thread_run](/images/tair-1/tair_conf_thread_run.png "config_server_thread::run")

接下来分析load_group_file函数，该函数主要功能是获取配置文件，当配置文件版本号发生变化后，就会调用该函数，获取最新的配置信息；上代码，在代码中添加注释：

![alt tair_conf_thread_run](/images/tair-1/load_group_file.png "config_server_thread::load_group_file")

在my_server_conf_thread的run函数中，若作为master运行的时候，检测到配置文件发生变化后，调用load_group_file来读取最新配置文件。在获取新的配置内容后，调用 send_group_file_packet函数将新的配置文件发送到slave上。因此在修改一个集群的配置文件时候，只需修改master的配置文件，修改后的内容会自动同步到slave服务器上。
 
###2.3 配置服务器状态检查
在my_server_conf_thread的run函数中，周期性检查配置服务器和数据服务器的状态，若状态发生变化，则做相应处理。若作为主配置服务器运行，该函数检查备配置服务器的状态，能检查到2种状态变化：
<ul>
<li>1）备配置服务器down掉，不需发送主备配置服务器切换；</li>
<li>2）备配置服务器up了，此时也不需要发生主备配置服务器切换；在这种情况下， 备份配置服务器需要和主配置服务同步数据； </li>
</ul>
若作为备配置服务器运行，则该函数将检查主配置服务器的状态，能检查到2种状态变化：
<ul>
<li>1）主配置服务器down了，发生主备配置服务器切换；</li>
<li>2）主配置服务器up，也发生主备配置服务器切换；若发生切换，作为主配置服务器运行的代码，会重新读取配配置文件；</li>
</ul>
检查配置服务器down掉的代码如下，可以看到判断配置服务器down掉的两个因素为：
<ul>
<li>据最近一次收到其心跳包的时间超过阈值, 这个阈值为 2 * TAIR_SERVER_DOWNTIME, TAIR_SERVER_DOWNTIME可配置;</li>
<li>无法ping通对端服务器;</li>
</ul>
__src/configserver/server_config_thread.cpp:__
<pre class="prettyprint lang-cc">
//如果超过TAIR_SERVER_DOWNTIME * 2时间内没有收到另外一个配置服务器的心跳包，该配置服务器如果其记录状态为alive，再次通过发送一个请求包到对端服务器，若对端服务器没有返回，则认为对端的配置服务器已经down了；
if(server_info_tmp->last_time < now && server_info_tmp->status == server_info::ALIVE) {        // downhost
  if(tbnet::ConnectionManager::isAlive(server_info_tmp->server_id) ==
      true)
    continue;
  server_info_tmp->status = server_info::DOWN;
  //若down掉的配置服务器，在配置文件中配置的为主配置服务器，则表示需要切换主配置服务器了
  if(i == 0)
    master_status_changed = true;
  log_warn("CONFIG HOST DOWN: %s",
      tbsys::CNetUtil::addrToString(server_info_tmp->server_id).
      c_str());
} 
</pre>
检测配置服务器从down的状态恢复过来, 检测条件也是类似的.

__src/configserver/server_config_thread.cpp:__
<pre class="prettyprint lang-cc">
//若在TAIR_SERVER_DOWNTIME * 2内收到了对端配置服务器的心跳包，并且当前记录状态为down，则修改其为alive。这表示另外一个配置服务器已经活过来了（或许是人工重新启动的）
if(server_info_tmp->last_time > now && server_info_tmp->status == server_info::DOWN) {        // uphost
  server_info_tmp->status = server_info::ALIVE;
  if(i == 0)
    master_status_changed = true;
  config_server_up = true;
  log_warn("CONFIG HOST UP: %s",
      tbsys::CNetUtil::addrToString(server_info_tmp->server_id).
      c_str());
}
</pre>
没有发生主配置服务器切换，并且备配置服务器起来了，需要将所有group的client version 和 server version都增加一个常量（这里是10）、
> 将版本号发生变化，强制更新所有客户端的对照表。

__src/configserver/server_config_thread.cpp:__
<pre class="prettyprint lang-cc">
if(master_status_changed == false) {
  if(config_server_up
      && master_config_server_id == util::local_server_ip::ip) {
    uint64_t slave_id = get_slave_server_id();
    group_info_map::iterator it; 
    group_info_rw_locker.rdlock();
    for(it = group_info_map_data.begin();
        it != group_info_map_data.end(); ++it) {
      // for we can't get peer's version from protocol, add 10 to client version and server
      it->second->inc_version(server_up_inc_step);
      it->second->send_server_table_packet(slave_id);
      log_warn("config server up and master not changed, version changed. "
          "group name: %s, client version: %u, server version: %u",
          it->second->get_group_name(), it->second->get_client_version(), it->second->get_server_version());
    }
    group_info_rw_locker.unlock();
  }
  //若没有发生主 备切换，这里将返回，这里需要注意的。
  return;
}
</pre>
发生主备切换，主要是主CS挂掉后，对外服务的功能由主CS切到备；或者主CS恢复后，切换回来。当发生主备切换后，需要重新加载配置文件。

__src/configserver/server_config_thread.cpp:__
<pre class="prettyprint lang-cc">
server_info *server_info_master = config_server_info_list[0];
if(server_info_master->status == server_info::ALIVE) {
  master_config_server_id = server_info_master->server_id;
}
else {
  master_config_server_id = util::local_server_ip::ip;
}
if(master_config_server_id == util::local_server_ip::ip) {

  //只有作为master的配置服务器才会执行下面代码,从本地配置文件中读取配置信息。这里为啥不将配置文件信息同步到备配置服务器上呢？
  const char *group_file_name =
    TBSYS_CONFIG.getString(CONFSERVER_SECTION, TAIR_GROUP_FILE, NULL);
  if(group_file_name == NULL) {
    log_error("not found %s:%s ", CONFSERVER_SECTION, TAIR_GROUP_FILE);
    return;
  }


  uint32_t curr_version = get_file_time(group_file_name);
  load_group_file(group_file_name, curr_version, 0);
}
log_warn("MASTER_CONFIG changed %s",
    tbsys::CNetUtil::addrToString(master_config_server_id).
    c_str());
}
</pre>
 
###2.4检查数据服务器状态
函数check_server_status函数完成数据服务器状态检查工作。check_server_status函数在server_conf_thread的run函数中被调用，周期性运行。其主要作以下工作：
<ul>
<li>1）标记出group_info发生变化了的group。configserver可以管理多个group, group的全局信息都保存在group_info数据结构中。</li>
<li>2）检查dataserver的状态；对于dataserver恢复运行后，根据配置策略不同而做不同处理；无论是检查到dataserver恢复或者挂掉，都需要重建对照表的。</li>
<li>3）检查数据迁移工作；在对照表建立后，configserver会判断出那些机器需要作数据迁移。数据迁移完成后，执行数据迁移的dataserver会向configserver报告数据迁移已完成，从而修改状态信息。</li>
</ul>

检查存储节点（数据服务器）的状态函数为server_conf_thread::check_server_status。该函数的调用关系如下：

![alt check_server_status](/images/tair-1/check_server_status.png "check_server_status")

图中红色部分是在满足特定条件下才执行的。在检查存储节点状态的过程中，会根据group的状态，检查是否需要重建对照表，若重建则将需要重建对照表的grou收集起来。这部分代码如下所示：
<pre class="prettyprint lang-cc">
set<group_info *>change_group_info_list;
//收集需要重新建立对照表的group，在调用该函数之前，在检查配置服务器状态的函数过程中，还有在初始化的时候，group_info_map被首次填，有可能改变group_info_map数据结构；
//当group的配置信息发生变化后，重建对照表标志就会被置位；
group_info_map::iterator it; 
for(it = group_info_map_data.begin(); it != group_info_map_data.end();
    ++it) {
  if(it->second->is_need_rebuild()) {
    change_group_info_list.insert(it->second);
  }   
}
</pre>
对于涉及更新对照表数据部分的代码，只有主CS才能执行，主CS会将新的对照表推送到备CS上，这样能够保证对照表的一致性。这部分代码如下：
<pre class="prettyprint lang-cc">
//only master config server can update hashtable.
if(master_config_server_id != util::local_server_ip::ip) {
  return;
}
//以下代码只会在主配置服务器中执行
uint64_t slave_server_id = get_slave_server_id();
</pre>

在check_server_status的代码中，会调用hard_check_migrate_complete函数，该函数会检查对照表m_hash和对照表d_hash是否完全相同, 若完全相同，则清空migrate_machine数据结构（该结构记录了哪些bucket需要迁移，以及迁移的目标节点）。而check_migrate_complete函数，同样要检测迁移是否完成，若没有完成，会打印出一些日志，通过日志可以看出当前还有多少bucket正在迁移。若迁移已经完成，执行如下动作：
<ul>
<li>1) 增加client_version, server_version的版本号;</li>
<li>2) 压缩对照表数据，同步到磁盘；</li>
<li>3) 将对照表发送到备配置服务器。</li>
</ul>
##小结
本节比较粗略的描述了configserver工作状态，主要介绍了：
<ul>
<li>configserver的初始化过程;</li>
<li>介绍各个线程循环
<ul>
<li> 1) 监听2个端口的线程;</li>
<li> 2) 线程池线程，这些线程等待请求包，并处理请求包;</li>
<li> 3) config_server_thread线程，该线程循环中主要处理对端配置服务器，数据存储节点状态发生变化后需要处理的事情.</li>
</ul>
</li>
</ul>
在configserver中，所谓的对照表是一个非常重要的事物，下一节讲描述configserver是如何创建对照表。TAIR源码分析<二>。
