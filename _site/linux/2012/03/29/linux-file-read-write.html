<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
	<head>
		<meta http-equiv="content-type" content="text/html;charset=utf-8" />
		<title>Linux 文件读写流程 - xanpeng</title>
		<link rel="stylesheet" type="text/css" href="/css/style.css" />
		<link rel="stylesheet" type="text/css" href="/css/syntax.css" />
	</head>

	<body>
		<div id="wrapper">
			<div id="content">
				<h2>Linux 文件读写流程</h2>
				<div class="cnt">
					<p><em>以ext3为例，查看文件读写流程。</em></p>

<h1>读</h1>

<p>用户程序调用glibc的read函数。</p>

<p>read()系统调用的实现是fs/read_write.c中的SYSCALL_DEFINE3(read)。它调用vfs_read()完成主要功能。</p>

<p>vfs_read()检查file->f_op->read函数指针是否为空，如果不为空则执行这个函数指针指向的函数。如果为空执行do_sync_read。<br/>
ext3_file_operations中就是将read指针定义为do_sync_read。</p>

<p>2.6内核增加了异步IO能力，运行用户空间发起IO操作，而不需要等待IO操作的完成。实现异步IO的file_operations方法，都使用kiocb控制块。<br/>
do_sync_read调用filp->f_op->aio_read，ext3的实现函数是generic_file_aio_read。</p>

<p>generic_file_aio_read判断f_flags是否包含<strong>O_DIRECT</strong>，如果包含，则执行direct IO(<em>direct IO的含义将在后文分析</em>)。<br/>
如果不是O_DIRECT，则做的是基于page-cache的读取。调用的是函数do_generic_file_read.</p>

<p>do_generic_file_read检查<strong>page-cache</strong>中是否有目标页面，如果存在则读取并返回；如果不存在就从磁盘读取，并在page-cache中也留一份。<br/>
从磁盘读取是由address_space->a_ops->readpage做的，它指向的函数是mpage_readpages。</p>

<p>mpage_readpages循环调用do_mpage_readpage，每次读取一个页面。这里可以看出，内核事实上是一个页面为单位从磁盘上读取数据的。<br/>
随着层层调用，最后执行到mpage_bio_submit，该函数调用submit_bio，至此读流程进入通用块设备层(Generic Block Layer)。</p>

<p>通用块设备层的工作此处略过，留待后面分析。</p>

<p><strong>Linux内核预读机制</strong></p>

<p>大多数磁盘操作是顺序的，且普通文件在磁盘上的存储一般都是占用连续的扇区。预读（read-ahead）就是在数据真正被访问之前，从普通文件或块设备文件中读取多个连续的文件页面到内存中。多数情况下，内核的预读机制可以明显地提高磁盘性能。<br/>
不过当进程的大多数访问是随机读时，预读是对系统有害的，因为浪费了内核cache空间。</p>

<p>预读算法：<br/>
- 批量<br/>
- 提前<br/>
- 预测：核心任务。<br/>
  Linux，FreeBSD等主流OS都遵循一个简单有效的原则，即把读模式分为<strong>随机读</strong>和<strong>顺序读</strong>两大类，并只对顺序读进行预读。</p>

<p>内核判断两次读访问是顺序的标准是：请求的第一个页面与上次访问的最后一个页面是相邻的。访问一个给定的文件，预读算法使用两个页面集-当前窗口（current window）和前进窗口（ahead window），算法的细节此处略过。</p>

<h1>写</h1>

<p>用户程序调用write，一般由glibc write代理调用内核的系统调用。</p>

<p>write系统调用的实现位于fs/read_write.c的SYSCALL_DEFINE3(write)，它调用vfs_write。</p>

<p>vfs_write检查file->f_op->write是否为空，如果为空执行do_sync_write，不过ext3中这个函数指针指向的也是do_sync_write。</p>

<p>do_sync_write执行filep->f_op->aio_write，也就是generic_file_aio_write，它调用__generic_file_aio_write。</p>

<p>__generic_file_aio_write中判断是否为O_DIRECT（unlikely），不是则执行generic_file_buffered_write，它调用generic_perform_write。</p>

<p>generic_perform_write调用address_space->a_ops->write_begin和address_space->a_ops->write_end，ext3中分别指向ext3_write_begin和（ext3_ordered_write_end，ext3_writeback_write_end，ext3_journalled_write_end）之一。</p>

<p>（后续暂略）</p>

<p><strong>内核刷新脏页机制</strong><br/>
generic_file_buffered_write执行完之后，会逐层返回直至系统调用结束。但此时要写的数据，只是拷贝到内核缓冲区，并将相应的页面标记为脏，并未真正写到磁盘上。<br/>
在下面条件下把脏页写回磁盘：<br/>
- page-cache太满或脏页数量非常大；<br/>
- 脏页停留在内存中的时间过长；<br/>
- 某个进程要求更改的块设备或文件数据被刷新，通常通过调用sync，fsync，fdatasync来实现。</p>

<p><strong>pdflush内核线程</strong><br/>
它有两个作用：<br/>
1、系统地扫描page-cache，以找到要刷新的脏页；<br/>
2、保证所有的页不会长期处于dirty状态。</p>

<p>系统中pdflush线程数量是动态变化的，太少时就创建新的，太多时就杀死部分。在系统空闲内存低于一个特定的阈值时，pdflush将脏页刷新回磁盘。</p>

<p><em>Many thanks to the cannot-named hacker.</em></p>

					--EOF--
				</div>
				<div id="disqus_thread"></div>
				<script type="text/javascript">
				  (function() {
				   var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
				   dsq.src = 'http://xanpeng.disqus.com/embed.js';
				   (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
				  })();
				</script>
				<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript=lzyyblog">comments powered by Disqus.</a></noscript>
			</div>
	</body>
</html>

